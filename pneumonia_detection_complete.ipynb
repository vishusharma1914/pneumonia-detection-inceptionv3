{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishusharma1914/pneumonia-detection-inceptionv3/blob/main/pneumonia_detection_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bPsS1Qm8Yo6"
      },
      "source": [
        "# Pneumonia Detection using InceptionV3\n",
        "**Submitted by:** Vishu Sharma\n",
        "**Date:** 08 July 2025\n"
      ],
      "id": "_bPsS1Qm8Yo6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A672lc-l8Yo7"
      },
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n"
      ],
      "id": "A672lc-l8Yo7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-5hcPnz8Yo8"
      },
      "source": [
        "# Load the PneumoniaMNIST dataset\n",
        "path = tf.keras.utils.get_file(\n",
        "    'pneumoniamnist.npz',\n",
        "    'https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1'\n",
        ")\n",
        "data = np.load(path)\n",
        "x_train, y_train = data['train_images'], data['train_labels']\n",
        "x_val, y_val = data['val_images'], data['val_labels']\n",
        "x_test, y_test = data['test_images'], data['test_labels']"
      ],
      "id": "S-5hcPnz8Yo8",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqt99rsV8Yo8"
      },
      "source": [
        "# Preprocess images: resize to 150x150 and convert grayscale to RGB\n",
        "def preprocess_images(images):\n",
        "    images = np.stack([images]*3, axis=-1)  # Convert to 3-channel\n",
        "    images = tf.image.resize(images, [150, 150]).numpy()\n",
        "    return images / 255.0\n",
        "\n",
        "x_train = preprocess_images(x_train)\n",
        "x_val = preprocess_images(x_val)\n",
        "x_test = preprocess_images(x_test)"
      ],
      "id": "Hqt99rsV8Yo8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX2FBg6Z8Yo8"
      },
      "source": [
        "# Create the InceptionV3 model\n",
        "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "id": "aX2FBg6Z8Yo8",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6UKEKpW8Yo8"
      },
      "source": [
        "# Compute class weights to handle imbalance\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}"
      ],
      "id": "c6UKEKpW8Yo8",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example preprocessing\n",
        "x_train = tf.image.resize(x_train, [150, 150])\n",
        "x_val = tf.image.resize(x_val, [150, 150])\n",
        "\n",
        "# If images are grayscale (1 channel), convert to RGB (3 channels)\n",
        "if x_train.shape[-1] == 1:\n",
        "    x_train = tf.image.grayscale_to_rgb(x_train)\n",
        "    x_val = tf.image.grayscale_to_rgb(x_val)\n"
      ],
      "metadata": {
        "id": "2h95rXkq9AUJ"
      },
      "id": "2h95rXkq9AUJ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4TUIyTrf8Yo8",
        "outputId": "66f28fa8-1da2-4d5a-cf61-bc8f1fb37341"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=3,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "id": "4TUIyTrf8Yo8",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 2s/step - accuracy: 0.7492 - loss: 0.6603 - val_accuracy: 0.8931 - val_loss: 0.2880\n",
            "Epoch 2/3\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 2s/step - accuracy: 0.8858 - loss: 0.3268 - val_accuracy: 0.9198 - val_loss: 0.2172\n",
            "Epoch 3/3\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 2s/step - accuracy: 0.8936 - loss: 0.2977 - val_accuracy: 0.9065 - val_loss: 0.2875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dyeXQeN8Yo8",
        "outputId": "e40ff705-a8ed-449d-8f98-9181c54c4373"
      },
      "source": [
        "# Evaluate the model\n",
        "preds = model.predict(x_test)\n",
        "y_pred = (preds > 0.5).astype(int)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, preds))"
      ],
      "id": "5dyeXQeN8Yo8",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.77      0.80       234\n",
            "           1       0.87      0.91      0.89       390\n",
            "\n",
            "    accuracy                           0.86       624\n",
            "   macro avg       0.85      0.84      0.85       624\n",
            "weighted avg       0.86      0.86      0.86       624\n",
            "\n",
            "F1 Score: 0.8897243107769424\n",
            "AUC: 0.9253889984659215\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}